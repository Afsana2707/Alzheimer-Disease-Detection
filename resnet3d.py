# -*- coding: utf-8 -*-
"""ResNet3D.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tgUSrHVwRsEc4507NPx7RIFG2AHIshcl

Early Alzhimer's Detection
---

About the project

i have already converted the OASIS MRI images from .img format into .nifti format using FSL and uploaded the files into github
now cloaning the files from github to get the mri images in the nifti forat from our model
"""

!git clone https://github.com/blackpearl006/OASIS_nifti_Part_1
!git clone https://github.com/blackpearl006/OASIS_nifti_Part_2
!git clone https://github.com/blackpearl006/OASIS_nifti_Part_3
!git clone https://github.com/blackpearl006/OASIS_nifti_Part_4
!git clone https://github.com/blackpearl006/OASIS_nifti_Part_5
!git clone https://github.com/blackpearl006/OASIS_nifti_Part_6
!git clone https://github.com/blackpearl006/OASIS_nifti_Part_7

"""### Importing necessary libraries"""

import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import nibabel as nib
from sklearn.metrics import confusion_matrix
import seaborn as sns

"""The librarires related to pytorch"""

from torch.utils.data import random_split
from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor
from torch.nn.parallel import DataParallel
from torchvision.transforms import ToTensor
from torch.utils.data import WeightedRandomSampler
import torch.optim as optim

"""Reading the additional info csv file for classify the MRI images into diffrent classes based on MMSE

Excerpt from the Facts sheet along with the dataset
Clinical
Mini-Mental State Examination (MMSE) (Rubin et al., 1998), Clinical Dementia Rating (CDR; 0=
nondemented; 0.5 - very mild dementia; 1 = mild dementia; 2 = moderate dementia) (Morris, 1993). All
participants with dementia (CDR >0) were diagnosed with probable AD.

based in this we classify the MRI images into 2 classes

Class 0 : Non Demented Class 1 : Probable AD

"""

metadata = pd.read_csv('/content/kaggle.csv')
metadata.head(5)

"""## Class Overview

The `CustomDataset` class is a fundamental component of our analysis pipeline. Let's break down its key components and methods:

### Input and Output

- **Input**: The class takes in dataset links, organized in parts. Additionally, a CSV file path containing class labels is provided, along with an optional transformation function.
- **Output**: The class yields normalized MRI images in tensor format, along with their corresponding labels.

### Method 1: `__getitem__()`

This method is the heart of data retrieval and preprocessing:

1. **Load MRI**: Using the file path provided, the method employs the `nibabel` library to load a brain MRI, resulting in a `numpy.ndarray`.

2. **Preprocessing**: The loaded MRI data is passed through the `preprocess_data()` function to normalize it.

3. **Tensor Conversion**: The normalized data is converted into a `torch.float32` tensor.

4. **Label Assignment**: If available, the label associated with the image is retrieved from the loaded labels dictionary.

5. **Return**: The preprocessed tensor and its label are returned.

### Method 2: `get_file_paths()`

This method locates MRI image files in the provided dataset links. It ensures that exactly 100 images of each label are included, promoting a balanced dataset.

### Method 3: `load_class_labels()`

This method reads class labels from a CSV file. It creates a dictionary mapping patient IDs to their corresponding labels based on Clinical Dementia Rating (CDR) values.

### Method 4: `preprocess_data()`

This method normalizes the input numpy array, representing the MRI image. The normalization involves calculating mean and standard deviation, and then scaling the data.

"""

class CustomDataset():
    def __init__(self, repo_paths, csv_path, num_samples = 200, transform = None):
        self.filelabels = self.load_class_labels(csv_path)
        self.file_paths = self.get_file_paths(repo_paths)
        self.transform = transform

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        file_path = self.file_paths[idx]
        nifti_data = nib.load(file_path)
        data = nifti_data.get_fdata()
        preprocessed_data = self.preprocess_data(data)

        preprocessed_tensor = torch.tensor(preprocessed_data, dtype=torch.float32)

        transformed_tensor = preprocessed_tensor.unsqueeze(0)

        file_id = file_path.split('/')[-1][0:13]
        if self.filelabels is not None:
            label = torch.tensor(self.filelabels[file_id], dtype=torch.float32).unsqueeze(0)
            return transformed_tensor, label
        else:
            return transformed_tensor

    def get_file_paths(self, paths):
        file_paths = []
        class_count = { 0: 0 , 1: 0}
        max_data_point = 100
        for path in paths:
            scans = os.listdir(path)
            scans = [scan for scan in scans if scan[:4] == 'OAS1']
#             print(f'Scans from path {path} have been found and the total count is : {len(scans)}')
            for folder_name in scans:
                folder_path = os.path.join(path, folder_name)  # Corrected variable name here
#                 print(f'Inside the folder {folder_path}')
                if os.path.isdir(folder_path) :
                    for file_name in os.listdir(folder_path):
                        file_path = os.path.join(folder_path, file_name)
#                         print(f'File Path: {file_path}')
                        label = self.filelabels[file_path.split('/')[-1][0:13]]
                        if class_count[label] < max_data_point :
                            class_count[label]+=1
                            file_paths.append(file_path)

            if sum(class_count.values()) == 2 * max_data_point: break
        return file_paths


    def load_class_labels(self, csv_path):
        df = pd.read_csv(csv_path)
        class_labels = {}
        for _, row in df.iterrows():
            id_value = row['ID']
            cdr_value = row['CDR']
            class_labels[id_value] = 0 if pd.isna(cdr_value) or float(cdr_value) == 0.0 else 1
        return class_labels

    def preprocess_data(self, data):
        mean = data.mean()
        std = data.std()
        normalized_data = (data - mean) / std
        return normalized_data

    def calculate_class_weights(self):
        class_count = {0: 0, 1: 0}
        total_len = len(self.file_paths)
        for file_path in self.file_paths:
            label = self.filelabels[file_path.split('/')[-1][0:13]]
            class_count[label]+=1
        inverse_class_weights = [1 / class_count[0],1 / class_count[1]]
        return(inverse_class_weights)

    def weighted_samples(self, num_samples):
        class_weights = self.calculate_class_weights()
        dataset_weights = []
        for file_path in self.file_paths:
            label = self.filelabels[file_path.split('/')[-1][0:13]]
            dataset_weights.append(class_weights[label])

        weighted_random_sampler = WeightedRandomSampler(dataset_weights, num_samples = num_samples, replacement = True)
        return weighted_random_sampler

data_dirs = [
    '/content/OASIS_nifti_Part_1',
    '/content/OASIS_nifti_Part_2',
    '/content/OASIS_nifti_Part_3',
    '/content/OASIS_nifti_Part_4',
    '/content/OASIS_nifti_Part_5',
    '/content/OASIS_nifti_Part_6',
]
csv_path = '/content/kaggle.csv'

custom_dataset = CustomDataset(data_dirs, csv_path)
custom_dataset

import random
rand_idx = [random.randint(1,100) for i in range(1)]
for idx in rand_idx:
    data, label = custom_dataset[idx]
    print("Data File Name:", custom_dataset.file_paths[idx].split('/')[-1][:13])
    print("Label:", label)
    print("Shape:", data.shape)

import matplotlib.pyplot as plt
import torch

fig, axs = plt.subplots(1, 2, figsize=(10, 5))

for num, (i, j) in enumerate(custom_dataset):
    slice_idx = i.shape[2] // 2  # Assuming the slice index is the last dimension


    slice_data = i[0, :, :, slice_idx].numpy()  # Convert to NumPy array

    label = int(j.item())
    ax = axs[num % 2]  # Alternate between two subplots
    ax.imshow(slice_data, cmap='gray')
    ax.set_title(f'MRI Slice : Label : {label}')

    if num % 2 == 1:
        plt.tight_layout()
        plt.show()
        if num >= 3:
            break

if num % 2 == 0:
    plt.tight_layout()
    plt.show()

val_size = int(len(custom_dataset) * 0.20)
train_size = len(custom_dataset) - val_size

train_ds, val_ds = random_split(custom_dataset, [train_size, val_size])

class_count = {0: 0, 1: 0}
total_count = 0
for data, label in train_ds:
    total_count+=1
    class_count[int(label.item())]+=1

inverse_class_weights = [1 / class_count[0],1 / class_count[1]]
inverse_class_weights

dataset_weights = []
for _, label in train_ds:
    dataset_weights.append(inverse_class_weights[int(label.item())])

num_samples = 400
weighted_random_sampler = WeightedRandomSampler(dataset_weights, num_samples = num_samples, replacement = True)

train_dl = DataLoader(train_ds, batch_size=4, sampler = weighted_random_sampler)
val_dl = DataLoader(val_ds, batch_size=4)
print('Using DataLoaders to Load the training and validation dataset')

print(f'Length of Training Dataset : {len(train_dl)*4}')
print(f'Length of Validation Dataset : {len(val_dl)*4}')
print(f'batch Size : {4}, With higher batch size we cannot train our model on GPU')

"""
>
> nn.Conv3d expects the input to have size [batch_size, channels, depth, height, width]. The first convolution expects 3 channels, but with your input having size [100, 16, 16, 16, 3], that would be 16 channels.
>
> Assuming that your data is given as [batch_size, depth, height, width, channels], you need to swap the dimensions around, which can be done with torch.Tensor.permute:
>
>  From: [batch_size, depth, height, width, channels]
>  To: [batch_size, channels, depth, height, width]
> input = input.permute(0, 4, 1, 2, 3)
>
"""

import torch.nn as nn

class CNN_baseline(nn.Module):
    def __init__(self):
        super().__init__()

        # Convolution layer for input size (128 x 256 x 256)
        self.network = nn.Sequential(
            nn.Conv3d(1, 8, kernel_size=3, padding=1),
            nn.BatchNorm3d(8),
            nn.ReLU(),
            nn.MaxPool3d(4),

            nn.Flatten(),
            nn.Linear(8 * 32 * 64 * 64, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, 4),
            nn.Softmax(dim=1)
        )

    def forward(self,x):
        return self.network(x)

# model = CNN_baseline()

import torch.nn as nn

class CNN_network(nn.Module):
    def __init__(self):
        super().__init__()

        # Convolution layer for input size (128 x 256 x 256)
        self.network = nn.Sequential(
            nn.Conv3d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm3d(32),
            nn.ReLU(),
            nn.Conv3d(32, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(32),
            nn.ReLU(),
            nn.MaxPool3d(2), # 32 x 64 x 128 x 128

            nn.Conv3d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(),
            nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(),
            nn.MaxPool3d(2), # 64 x 32 x 64 x 64

            nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(128),
            nn.ReLU(),
            nn.Conv3d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(128),
            nn.ReLU(),
            nn.MaxPool3d(2), # 128 x 16 x 32 x 32

            nn.Conv3d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(256),
            nn.ReLU(),
            nn.Conv3d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(256),
            nn.ReLU(),
            nn.MaxPool3d(2), # 256 x 8 x 16 x 16

            nn.Conv3d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(512),
            nn.ReLU(),
            nn.Conv3d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm3d(512),
            nn.ReLU(),
            nn.MaxPool3d(2), #512 x 4 x 8 x 8


            nn.Flatten(),
            nn.Linear(512 * 4 * 8 * 8, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Linear(64, 1)
#             nn.Sigmoid()
        )

    def forward(self,x):
        return self.network(x)

# model = CNN_network()

import torch.nn as nn

class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvBlock, self).__init__()
        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm3d(out_channels)
        self.relu1 = nn.ReLU()
        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm3d(out_channels)
        self.relu2 = nn.ReLU()

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu1(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu2(out)
        return out

# The contracting path follows the typical architecture of a convolutional network.
# It consists of the repeated application of two 3×3 convolutions (unpadded convolutions),
# each followed by a ReLU and a 2×2 max pooling operation with stride 2 for downsampling.
# At each downsampling step we double the number of feature channels.

class EncoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(EncoderBlock, self).__init__()
        self.conv1 = ConvBlock(in_channels, out_channels)
#         self.bn1 = nn.BatchNorm3d(out_channels)
        self.maxpool = nn.MaxPool3d(2)

    def forward(self, x):
        conv_out = self.conv1(x)
        out = self.maxpool(conv_out)
        return conv_out, out

# Every step in the expansive path consists of an upsampling of the feature map
# followed by a 2×2 convolution (“up-convolution”) that halves the number of feature channels,
# A concatenation with the correspondingly cropped feature map from the contracting path,
# and two 3×3 convolutions, each followed by a ReLU

class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DecoderBlock, self).__init__()
        self.up = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, padding=0)
        self.conv = ConvBlock(out_channels+out_channels, out_channels)


    def forward(self, x, skip):
        conv_up = self.up(x)
        print("conv_up shape:", conv_up.shape)
        print("skip shape:", skip.shape)
        out = torch.cat([conv_up, skip], dim=1)
        out = self.conv(out)
        return out

class Classifier(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Classifier, self).__init__()
        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size = 1, padding = 0)

    def forward(self, x):
        out = self.conv(x)
        return out


class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()

        self.encode_block1 = EncoderBlock(1, 64)
        self.encode_block2 = EncoderBlock(64, 128)
        self.encode_block3 = EncoderBlock(128, 256)
#         self.encode_block4 = EncoderBlock(256, 512)

        self.bottleneck = ConvBlock(256, 512)

#         self.decode_block1 = DecoderBlock(1024, 512)
        self.decode_block2 = DecoderBlock(512, 256)
        self.decode_block3 = DecoderBlock(256, 128)
        self.decode_block4 = DecoderBlock(128, 64)

        self.output = Classifier(64, 1)


    def forward(self, x):
        s1, x1, = self.encode_block1(x)
        s2, x2 = self.encode_block2(x1)
        s3, x3 = self.encode_block3(x2)

        x7 = self.decode_block2(x6, s3)
        x8 = self.decode_block3(x7, s2)
        x9 = self.decode_block4(x8, s1)

        out = self.output(x9)

        return out

# model = UNet()

import torch
import torch.nn as nn

# Basic Block for 3D ResNet-18
class BasicBlock3D(nn.Module):
    expansion = 1

    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(BasicBlock3D, self).__init__()
        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm3d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm3d(out_channels)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out

# 3D ResNet-18 model
class ResNet18_3D(nn.Module):
    def __init__(self, num_classes=1):
        super(ResNet18_3D, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm3d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)

        # Residual blocks
        self.layer1 = self._make_layer(BasicBlock3D, 64, 2, stride=1)
        self.layer2 = self._make_layer(BasicBlock3D, 128, 2, stride=2)
        self.layer3 = self._make_layer(BasicBlock3D, 256, 2, stride=2)
        self.layer4 = self._make_layer(BasicBlock3D, 512, 2, stride=2)

        # Classifier
        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.fc = nn.Linear(512 * BasicBlock3D.expansion, num_classes)

    def _make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if stride != 1 or self.in_channels != out_channels * block.expansion:
            downsample = nn.Sequential(
                nn.Conv3d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm3d(out_channels * block.expansion),
            )

        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels * block.expansion
        for _ in range(1, blocks):
            layers.append(block(self.in_channels, out_channels))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)

        return x

# Instantiate the 3D ResNet-18 model
model = ResNet18_3D()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device = "cpu"
model = model.to(device)

model = DataParallel(model)

class_count[1]

inverse_class_weights = torch.tensor([total_count / (2*class_count[1])],dtype=torch.float32)
inverse_class_weights

inverse_class_weights = inverse_class_weights.to(device)
criterion =  nn.BCEWithLogitsLoss(pos_weight = inverse_class_weights )
# criterion =  nn.BCEWithLogitsLoss()

# Define the optimizer
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Define the number of epochs
num_epochs = 10

print(f'criterion =  nn.BCELoss(), optimizer = optim.Adam(model.parameters()), num_epochs = 25')

# Training loop
train_losses = []
val_losses = []
train_accu = []
val_accu = []
model_save_path = '/content/model.pth'

for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    train_correct = 0
    train_total = 0

    for inputs, labels in train_dl:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        predicted = (outputs >= 0.5)
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()

        train_loss += loss.item()

    train_accuracy = 100 * train_correct / train_total

    # Validation phase
    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for inputs, labels in val_dl:
            inputs = inputs.to(device)
            labels = labels.to(device)

            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Compute validation accuracy
            predicted = (outputs >= 0.5)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

            val_loss += loss.item()

    val_accuracy = 100 * val_correct / val_total

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accu.append(train_accuracy)
    val_accu.append(val_accuracy)
    # Print epoch statistics
    print(f"Epoch [{epoch+1}/{num_epochs}]: "
          f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, "
          f"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%")

torch.save(model, model_save_path)

torch.save(model.state_dict(), 'trained_model_state.pth')

from google.colab import files
files.download('/content/model.pth')

torch.cuda.empty_cache()

train_losses

epochs = list(range(1, len(train_losses) + 1))

# plt.plot(epochs, train_losses, marker='o')
# plt.plot(epochs, val_losses, marker='o')
# plt.title('Traning and Validation Losses Curve')
# plt.xlabel('Epoch')
# plt.ylabel('Loss')
# plt.ylim(0, 100)
# plt.grid(False)
# plt.gcf().set_facecolor('white')
# plt.show()

plt.plot(epochs, train_losses, marker='o')
plt.title('Training Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim(0, 100)
plt.figure(facecolor='none')
plt.show()

plt.plot(epochs, val_losses, marker='o', color = 'orange')
plt.title('Validation Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim(0, 10)
plt.show()

plt.plot(epochs, train_accu, marker='o')
plt.plot(epochs, val_accu, marker='o')
plt.title('Traning and Validation Accuracy Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim(0,100)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

num_classes = 2
conf_matrix = np.zeros((num_classes, num_classes), dtype=int)

model.eval()

with torch.no_grad():
    for inputs, labels in train_dl:
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = model(inputs)
        predicted = (outputs >= 0.5).int()  # Convert to int (0 or 1)

        conf_matrix += confusion_matrix(labels.cpu(), predicted.cpu(), labels=[0, 1])


TP = conf_matrix[1, 1]
FP = conf_matrix[0, 1]
FN = conf_matrix[1, 0]

precision = TP / (TP + FP)
recall = TP / (TP + FN)

# plt.text(0.5, -0.1, f'Precision: {precision:.4f}', horizontalalignment='center', verticalalignment='center',
#          transform=plt.gca().transAxes)
# plt.text(0.5, -0.2, f'Recall: {recall:.4f}', horizontalalignment='center', verticalalignment='center',
#          transform=plt.gca().transAxes)

plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["True 0", "True 1"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.suptitle(f'Precision: {precision:.4f}, Recall: {recall:.4f}')
plt.show()

num_classes = 2
conf_matrix = np.zeros((num_classes, num_classes), dtype=int)

model.eval()

with torch.no_grad():
    for inputs, labels in val_dl:
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = model(inputs)
        predicted = (outputs >= 0.5).int()  # Convert to int (0 or 1)

        conf_matrix += confusion_matrix(labels.cpu(), predicted.cpu(), labels=[0, 1])


TP = conf_matrix[1, 1]
FP = conf_matrix[0, 1]
FN = conf_matrix[1, 0]

precision = TP / (TP + FP)
recall = TP / (TP + FN)

plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["True 0", "True 1"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.suptitle(f'Precision: {precision:.4f}, Recall: {recall:.4f}')
plt.show()

